---
title: DecisionTree
tags: DT ML 
categories:
- Data Mining
- Tree
---



# 决策树

To be or not to be, this is a question.



## 三要素

此节主要是对《统计学习方法》 李航一书决策树章节的一些摘要与衍生思考， 如果没有指定来源，则应用部分全来着此书。



机器学习有三要素，模型，策略和算法。普通决策树的三要素可总结如下。

### 模型

> 决策树由结点（node）和有向边（directed edge）组成， 节点分为两种类型，内部节点（internal node）和叶子节点（leaf nod）。

决策树模型可以想象为一颗倒立生长的树，由根节点开始，向下长出枝桠连接子节点，最后长出叶子。

其**模型**由多个节点构成： **普通节点**中储存连接下一节点的条件，**叶子节点**中储存最终分类的值。

输入一个样本，样本数据从根节点开始，按照划分条件找到下一节点，直到叶子节点， 此叶子节点的值即为样本对应的预测结果。

![1591517816351](DecisionTree.assets/1591517816351.png)

### 策略

使用什么样的策略去评估决策树的好坏呢？ 

> 决策树学习的损失函数通常是正则化的极大似然函数， 而学习策略就是以损失函数为目标函数的最小化。



### 算法

> 从所有可能的决策树中选取最优决策树为NP完全问题，所以现实中决策树算法通常采用启发式的方法，近似求解这一最优解。这样得到的决策树是次优的（sub-optimal）

[P问题NP问题NPC问题](<https://baike.baidu.com/item/NP%E5%AE%8C%E5%85%A8%E9%97%AE%E9%A2%98/4934286?fr=aladdin>)

> 启发式算法（heuristic algorithm)是相对于[最优化](https://baike.baidu.com/item/%E6%9C%80%E4%BC%98%E5%8C%96)算法提出的。一个问题的最优算法求得该问题每个实例的[最优解](https://baike.baidu.com/item/%E6%9C%80%E4%BC%98%E8%A7%A3/5208902)。启发式算法可以这样定义：**一个基于直观或经验构造的算法**，在可接受的花费（指计算时间和空间）下给出待解决组合优化问题每一个实例的一个[可行解](https://baike.baidu.com/item/%E5%8F%AF%E8%A1%8C%E8%A7%A3/962143)，该可行解与最优解的偏离程度**一般不能被预计**。现阶段，启发式算法以仿自然体算法为主，主要有[蚁群算法](https://baike.baidu.com/item/%E8%9A%81%E7%BE%A4%E7%AE%97%E6%B3%95/9646604)、[模拟退火法](https://baike.baidu.com/item/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E6%B3%95/10423893)、[神经网络](https://baike.baidu.com/item/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/16600562)等。

 